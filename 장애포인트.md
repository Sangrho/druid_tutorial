## 장애포인트
Druid 는 내부에 많은 어플리케이션이 있으며 외부로도 많은 Dependency가 있다.
따라서 서로 간에 영향도를 미리 파악하고, 장애 발생시 맥을 짚어야 하는 포인트를 알아야만 한다.

## 장애포인트 세부

1.Zookeeper<br/>
죽기전 알고 있던 클러스터와 통신하기 때문에,쿼리 수행이 가능하다.<br/>
왜냐하면Broker가 Zookeeper가 죽기 전후의 클러스터는 바뀌지 않을거라 생각 하기 때문이다.<br/><br/>

2.Coordinator<br/>
Segment Granularity 가1hour로 되어있다는 가정하에,현재 1시간동안은 문제 없이 수행되지만,다음 시간부터 균등하게 적재가 안된다.<br/>
왜냐하면 어느 노드에 얼만큼의 데이터가 축적되서,어디에 적재 해야 하는지에 대한 가이드를 못 해주기 때문이다.<br/><br/>
3.META_DATA<br/>
이게 죽으면 엄청 치명적이다.그래서 AIH RT처럼 3중화(Percona)해놔야 한다.<br/>
오퍼레이션 정보를 MySQL에 저장한다.따라서 MySQL이 죽으면,새로운 세그먼트의 생성,오래된 세그먼트의 드랍등을 할 수 없게 된다.<br/>
나머지Broker, Historical등은 정상적으로 동작하지만,세그먼트의 업데이트는 이뤄지지 않는다.<br/>
20170706에 있었던 일인데,mysql이 test용으로 총 두개가 떠있고,coo,zoo가 바라보는거와 middle이 바라보는게 다를 경우 log로 남지도 않고 경험과 감으로 때려맞춰야만 한다.<br/><br/>
4.HDFS<br/>
이게 죽으면 Peon은 더이상 데이터를 Memory에 로드하지 못하며,Peon도 더이상 값을 넣지 못하기 때문에(Persist)Pending상태가 된다.또한 기존 데이터들은 모두 날라가게 된다.<br/>
replication 1일 경우,historical마저 죽으면 데이터가 다 날라간다.<br/><br/>
5.Historical Node<br/>
AIH에서도 있었던 일인데,해당 노드의 디스크가 꽉 찰 경우,꽉 찬 이후부터의 데이터에 대한 Query응답을 할 수 없게 된다.<br/>
안에 있던 세그먼트들은 다시 재 할당(수동)되어야 한다.대부분 캐파의 문제이므로 캐파를 잘 따져본다.<br/><br/>
